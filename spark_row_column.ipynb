{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaca90e2",
   "metadata": {},
   "source": [
    "# Row & Column class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072c2a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/20 09:17:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/20 09:17:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7520507",
   "metadata": {},
   "source": [
    "## Row Class\n",
    "\n",
    "- 하나의 row 데이터를 만들 때 사용할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a37565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfad6c8",
   "metadata": {},
   "source": [
    "### Create a Row Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1428542",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1=Row(\"James\",40)\n",
    "\n",
    "row2=Row(name=\"Alice\", age=11)\n",
    "\n",
    "Person = Row(\"name\", \"age\")\n",
    "p1=Person(\"James\", 40)\n",
    "p2=Person(\"Alice\", 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05aa2106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James 40\n",
      "Alice 11\n",
      "James 40\n"
     ]
    }
   ],
   "source": [
    "print(row1[0], row1[1])\n",
    "print(row2.name, row2.age)\n",
    "print(p1.name, p1.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2619cd0e",
   "metadata": {},
   "source": [
    "### Using Row class on PySpark RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "995c0744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='James,,Smith', lang=['Java', 'Scala', 'C++'], state='CA'), Row(name='Michael,Rose,', lang=['Spark', 'Java', 'C++'], state='NJ'), Row(name='Robert,,Williams', lang=['CSharp', 'VB'], state='NV')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "data = [Row(name=\"James,,Smith\",lang=[\"Java\",\"Scala\",\"C++\"],state=\"CA\"), \n",
    "    Row(name=\"Michael,Rose,\",lang=[\"Spark\",\"Java\",\"C++\"],state=\"NJ\"),\n",
    "    Row(name=\"Robert,,Williams\",lang=[\"CSharp\",\"VB\"],state=\"NV\")]\n",
    "\n",
    "rdd=spark.sparkContext.parallelize(data)\n",
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de03aa5",
   "metadata": {},
   "source": [
    "### Using Row class on PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020e02fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+-----+\n",
      "|            name|              lang|state|\n",
      "+----------------+------------------+-----+\n",
      "|    James,,Smith|[Java, Scala, C++]|   CA|\n",
      "|   Michael,Rose,|[Spark, Java, C++]|   NJ|\n",
      "|Robert,,Williams|      [CSharp, VB]|   NV|\n",
      "+----------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad1b9a",
   "metadata": {},
   "source": [
    "## Column Class\n",
    "\n",
    "- 데이터 처리/분석을 하다보면 컬럼 단위로 데이터를 다루는 경우가 많다\n",
    "- Spark DataFrame은 특정 컬럼에 접근하면 Column 클래스 객체를 돌려주고, Column 클래스 객체만의 데이터 처리/분석에 유용한 속성과 메서드를 제공해준다\n",
    "- Column Class 에 정의된 메서드 말고도 pyspark.sql.functions에서 제공하는 함수도 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff38858",
   "metadata": {},
   "source": [
    "### Create Column Class Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "022e2451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "colObj = lit(\"myspark\")\n",
    "type(colObj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd161275",
   "metadata": {},
   "source": [
    "###  Access the Column from DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b9902ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name.fname: string (nullable = true)\n",
      " |-- gender: long (nullable = true)\n",
      "\n",
      "+----------+------+\n",
      "|name.fname|gender|\n",
      "+----------+------+\n",
      "|     James|    23|\n",
      "|       Ann|    40|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(\"James\",23),(\"Ann\",40)]\n",
    "columns = [\"name.fname\", \"gender\"]\n",
    "\n",
    "df=spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "502c4c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.column.Column'>\n",
      "<class 'pyspark.sql.column.Column'>\n",
      "<class 'pyspark.sql.column.Column'>\n",
      "<class 'pyspark.sql.column.Column'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df.gender))\n",
    "print(type(df[\"gender\"]))\n",
    "print(type(df[\"`name.fname`\"])) # backticks for accessing column with dot\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "print(type(col(\"gender\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "936990c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|    23|\n",
      "|    40|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"gender\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab6f888",
   "metadata": {},
   "source": [
    "### PySpark Column Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13de74b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "| 100|   2|   1|\n",
      "| 200|   3|   4|\n",
      "| 300|   4|   4|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(100,2,1),(200,3,4),(300,4,4)]\n",
    "columns = [\"col1\", \"col2\", \"col3\"]\n",
    "df=spark.createDataFrame(data, schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae64e511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|(col1 + col2)|\n",
      "+-------------+\n",
      "|          102|\n",
      "|          203|\n",
      "|          304|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 - col2)|\n",
      "+-------------+\n",
      "|           98|\n",
      "|          197|\n",
      "|          296|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 * col2)|\n",
      "+-------------+\n",
      "|          200|\n",
      "|          600|\n",
      "|         1200|\n",
      "+-------------+\n",
      "\n",
      "+-----------------+\n",
      "|    (col1 / col2)|\n",
      "+-----------------+\n",
      "|             50.0|\n",
      "|66.66666666666667|\n",
      "|             75.0|\n",
      "+-----------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 % col2)|\n",
      "+-------------+\n",
      "|            0|\n",
      "|            2|\n",
      "|            0|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 > col3)|\n",
      "+-------------+\n",
      "|         true|\n",
      "|        false|\n",
      "|        false|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 < col3)|\n",
      "+-------------+\n",
      "|        false|\n",
      "|         true|\n",
      "|        false|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 = col3)|\n",
      "+-------------+\n",
      "|        false|\n",
      "|        false|\n",
      "|         true|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.col1 + df.col2).show()\n",
    "df.select(df.col1 - df.col2).show() \n",
    "df.select(df.col1 * df.col2).show()\n",
    "df.select(df.col1 / df.col2).show()\n",
    "df.select(df.col1 % df.col2).show()\n",
    "\n",
    "df.select(df.col2 > df.col3).show()\n",
    "df.select(df.col2 < df.col3).show()\n",
    "df.select(df.col2 == df.col3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af81c77",
   "metadata": {},
   "source": [
    "### PySpark Column Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "182d0926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(\"James\",\"Bond\",\"100\",None),\n",
    "      (\"Ann\",\"Varsa\",\"200\",'F'),\n",
    "      (\"Tom Cruise\",\"XXX\",\"400\",''),\n",
    "      (\"Tom Brand\",None,\"400\",'M')]\n",
    "columns=[\"fname\",\"lname\",\"id\",\"gender\"]\n",
    "\n",
    "df=spark.createDataFrame(data,columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420720b1",
   "metadata": {},
   "source": [
    "#### alias() & name() – Set’s name to Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6ec3e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+------+\n",
      "|     full_name| id|gender|\n",
      "+--------------+---+------+\n",
      "|    James Bond|100|  null|\n",
      "|     Ann Varsa|200|     F|\n",
      "|Tom Cruise XXX|400|      |\n",
      "|     Tom Brand|400|     M|\n",
      "+--------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "# (concat_ws() 는 두 문자열 컬럼을 붙이기 위한 함수이다)\n",
    "\n",
    "# Column.alias(<원하는 컬럼명>)\n",
    "# Column.name(<원하는 컬럼명>)\n",
    "\n",
    "df.select(concat_ws(\" \", df.fname, df.lname).alias(\"full_name\"), df.id, df.gender).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9686c",
   "metadata": {},
   "source": [
    "#### asc() & desc() – Sort the DataFrame columns by Ascending or Descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebbf7cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|       Ann|Varsa|200|     F|\n",
      "|     James| Bond|100|  null|\n",
      "| Tom Brand| null|400|     M|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column.asc(): 컬럼 기준 오름차순 정렬\n",
    "\n",
    "df.sort(df.fname.asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc796c0",
   "metadata": {},
   "source": [
    "#### cast() & astype() – Used to convert the data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccd5cc01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.fname,df.id.cast(\"int\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df78aee5",
   "metadata": {},
   "source": [
    "#### between() – Returns a Boolean expression when a column values in between lower and upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12d6cda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|((id >= 0) AND (id <= 300))|\n",
      "+---------------------------+\n",
      "|                       true|\n",
      "|                       true|\n",
      "|                      false|\n",
      "|                      false|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column.between(lower, upper)\n",
    "df.select(df.id.between(0, 300)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7012c3c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+------+\n",
      "|fname|lname| id|gender|\n",
      "+-----+-----+---+------+\n",
      "|James| Bond|100|  null|\n",
      "|  Ann|Varsa|200|     F|\n",
      "+-----+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.id.between(0, 300)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72090a41",
   "metadata": {},
   "source": [
    "#### contains() – Checks if a DataFrame column value contains a a value specified in this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86bd2cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---+------+\n",
      "|    fname|lname| id|gender|\n",
      "+---------+-----+---+------+\n",
      "|Tom Brand| null|400|     M|\n",
      "+---------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column.contains()\n",
    "df.filter(df.fname.contains(\"Brand\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2cf0bf",
   "metadata": {},
   "source": [
    "#### startswith() & endswith() – Checks if the value of the DataFrame Column starts and ends with a String respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b3ae73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+---------+-----+---+------+\n",
      "|    fname|lname| id|gender|\n",
      "+---------+-----+---+------+\n",
      "|Tom Brand| null|400|     M|\n",
      "+---------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column.startswith()\n",
    "# Column.endswith()\n",
    "\n",
    "df.filter(df.fname.startswith(\"T\")).show()\n",
    "df.filter(df.fname.endswith(\"Brand\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d040f976",
   "metadata": {},
   "source": [
    "#### isNull() & isNotNull() – Checks if the DataFrame column has NULL or non NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4099b646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---+------+\n",
      "|    fname|lname| id|gender|\n",
      "+---------+-----+---+------+\n",
      "|Tom Brand| null|400|     M|\n",
      "+---------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column.isNull()\n",
    "# Column.isNotNull()\n",
    "\n",
    "df.filter(df.lname.isNull()).show()\n",
    "df.filter(df.lname.isNotNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9428536",
   "metadata": {},
   "source": [
    "#### like() & rlike() – Similar to SQL LIKE expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a1bd398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column.like()\n",
    "# Column.rlike()\n",
    "\n",
    "df.filter(df.fname.like(\"%ise\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3719538f",
   "metadata": {},
   "source": [
    "#### substr() – Returns a Column after getting sub string from the Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "673f2a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|substr|\n",
      "+------+\n",
      "|    Ja|\n",
      "|    An|\n",
      "|    To|\n",
      "|    To|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column.substr()\n",
    "\n",
    "\n",
    "df.select(df.fname.substr(1,2).alias(\"substr\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0eaefe",
   "metadata": {},
   "source": [
    "#### when() & otherwise() – It is similar to SQL Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe49e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|gender|full_gender|\n",
      "+------+-----------+\n",
      "|  null|       null|\n",
      "|     F|     Female|\n",
      "|      |           |\n",
      "|     M|       Male|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# when() can only be applied on a Column previously generated by when() function\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df.select(df.gender, when(df.gender==\"M\",\"Male\").when(df.gender==\"F\", \"Female\") \\\n",
    "                                                  .when(df.gender==None, \"None\") \\\n",
    "                                                  .otherwise(df.gender).alias(\"full_gender\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5401265",
   "metadata": {},
   "source": [
    "#### isin() – Check if value presents in a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "868ece1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+------+\n",
      "|fname|lname| id|gender|\n",
      "+-----+-----+---+------+\n",
      "|James| Bond|100|  null|\n",
      "|  Ann|Varsa|200|     F|\n",
      "+-----+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "li=[\"100\",\"200\"]\n",
    "df.filter(df.id.isin(li)) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b8435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
