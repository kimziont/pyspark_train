{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e8cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed93eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/20 04:27:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369a901c",
   "metadata": {},
   "source": [
    "# Creating PySpark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531267a",
   "metadata": {},
   "source": [
    "- RDD, list, DataFrame\n",
    "- TXT, CSV, JSON, ORV, Avro, Parquet, XML formats by reading from HDFS, S3, DBFS, Azure Blob file systems\n",
    "- Kafka, MongoDB, MySQL, .. reading data from RDBMS Databases and NoSQL databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df55ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\",\"users_count\"]\n",
    "data = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2b5319",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f24ccf2",
   "metadata": {},
   "source": [
    "## Create DataFrame from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a8c7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toDF()\n",
    "# create a DataFrame from the existing RDD\n",
    "dfFromRDD1 = rdd.toDF(columns)\n",
    "\n",
    "# createDataFrame()\n",
    "# dfFromRDD2 = spark.createDataFrame(rdd, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7ea211f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- users_count: long (nullable = true)\n",
      "\n",
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD1.printSchema()\n",
    "dfFromRDD1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e1b80",
   "metadata": {},
   "source": [
    "### ✿ PySpark StructType & StructField"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32277161",
   "metadata": {},
   "source": [
    "- By default, the datatype of these columns infers to the type of data. \n",
    "- We can change this behavior by supplying schema, where we can specify a column name, data type, and nullable for each field/column.\n",
    "- specify the schema to the DataFrame and create complex columns like nested struct, array, and map column\n",
    "- https://sparkbyexamples.com/pyspark/pyspark-structtype-and-structfield/ 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7cc90a",
   "metadata": {},
   "source": [
    "-  StructField: defines column name, column data type, boolean to specify if the field can be nullable or not and metadata.\n",
    "- StructType: a collection of StructFields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60e0188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e4ac3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"fields\":[{\"metadata\":{},\"name\":\"firstname\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"middlename\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"lastname\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"id\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"gender\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"salary\",\"nullable\":true,\"type\":\"integer\"}],\"type\":\"struct\"}'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    " \n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False) # truncate=False: 모든 컬럼 보고 싶을 때\n",
    "df.schema.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c72e4",
   "metadata": {},
   "source": [
    "## Create DataFrame from List Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1eb8c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|   id|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|    James|          |   Smith|36636|     M|  3000|\n",
      "|  Michael|      Rose|        |40288|     M|  4000|\n",
      "|   Robert|          |Williams|42114|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|39192|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# createDataFrame()\n",
    "columns = ['firstname', 'middlename', 'lastname', 'id', 'gender', 'salary']\n",
    "dfFromData2 = spark.createDataFrame(data, columns)\n",
    "\n",
    "dfFromData2.printSchema()\n",
    "dfFromData2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb12520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    " \n",
    "dfFromData3 = spark.createDataFrame(data=data,schema=schema)\n",
    "\n",
    "dfFromData3.printSchema()\n",
    "dfFromData3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fb6472",
   "metadata": {},
   "source": [
    "## Create DataFrame from Data sources\n",
    "\n",
    "- In real-time mostly you create DataFrame from data source files like CSV, Text, JSON, XML e.t.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8499c195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n",
      "+-----+------+---+\n",
      "| name|gender|age|\n",
      "+-----+------+---+\n",
      "| Mike|  Male| 24|\n",
      "|Sujan|Female| 27|\n",
      "| Deli|  Male| 32|\n",
      "| Kahl|  Male| 17|\n",
      "| Rosa|Female| 51|\n",
      "+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField(\"name\", StringType(), True), \\\n",
    "                     StructField(\"gender\", StringType(), True), \\\n",
    "                     StructField(\"age\", IntegerType(), True)])\n",
    "\n",
    "df_csv = spark.read.csv('./test.csv', schema=schema, header=True)\n",
    "\n",
    "df_csv.printSchema()\n",
    "df_csv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a623ff22",
   "metadata": {},
   "source": [
    "## Create an Empty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4105eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty_no_schema = spark.createDataFrame([], StructType([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41b9b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty_with_schema = spark.createDataFrame([], schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ada53984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "\n",
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_empty_no_schema.printSchema()\n",
    "df_empty_no_schema.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50f8cef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n",
      "+----+------+---+\n",
      "|name|gender|age|\n",
      "+----+------+---+\n",
      "+----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_empty_with_schema.printSchema()\n",
    "df_empty_with_schema.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efa720",
   "metadata": {},
   "source": [
    "## Convert PySpark RDD to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "492ebbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d41d4cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|  Finance|     10|\n",
      "|Marketing|     20|\n",
      "|    Sales|     30|\n",
      "|       IT|     40|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RDD.toDF()\n",
    "\n",
    "columns = [\"dept_name\",\"dept_id\"]\n",
    "\n",
    "df = rdd.toDF(columns)\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85b52a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|  Finance|     10|\n",
      "|Marketing|     20|\n",
      "|    Sales|     30|\n",
      "|       IT|     40|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# createDataFrame(RDD)\n",
    "\n",
    "df = spark.createDataFrame(rdd, columns)\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e73b4cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: integer (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|  Finance|     10|\n",
      "|Marketing|     20|\n",
      "|    Sales|     30|\n",
      "|       IT|     40|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField(\"dept_name\", StringType(), True), \\\n",
    "                    StructField(\"dept_id\", IntegerType(), True)])\n",
    "\n",
    "df = spark.createDataFrame(rdd, schema)\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bceedc",
   "metadata": {},
   "source": [
    "### ✿ Convert PySpark DataFrame to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4a674",
   "metadata": {},
   "source": [
    "- operations on Pyspark run faster than Pandas due to its distributed nature and parallel execution on multiple cores and machines\n",
    "- If you are working on a Machine Learning application where you are dealing with larger datasets, PySpark processes operations many times faster than pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "23b3ec8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- middle_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "|first_name|middle_name|last_name|id   |gender|salary|\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "|James     |           |Smith    |36636|M     |3000  |\n",
      "|Michael   |Rose       |         |40288|M     |4000  |\n",
      "|Robert    |           |Williams |42114|M     |4000  |\n",
      "|Maria     |Anne       |Jones    |39192|F     |4000  |\n",
      "|Jen       |Mary       |Brown    |     |F     |-1    |\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['first_name', 'middle_name', 'last_name', 'id', 'gender', 'salary']\n",
    "\n",
    "pysparkDF = spark.createDataFrame(data = data, schema = columns)\n",
    "pysparkDF.printSchema()\n",
    "pysparkDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2626ee7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "  first_name middle_name last_name     id gender  salary\n",
      "0      James                 Smith  36636      M    3000\n",
      "1    Michael        Rose            40288      M    4000\n",
      "2     Robert              Williams  42114      M    4000\n",
      "3      Maria        Anne     Jones  39192      F    4000\n",
      "4        Jen        Mary     Brown             F      -1\n"
     ]
    }
   ],
   "source": [
    "# PySparkDF.toPandas()\n",
    "\n",
    "pandasDF = pysparkDF.toPandas()\n",
    "print(type(pandasDF))\n",
    "print(pandasDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
